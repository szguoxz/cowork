# Cowork Configuration Example
#
# Copy this file to:
#   Linux:   ~/.config/cowork/config.toml
#   macOS:   ~/Library/Application Support/cowork/config.toml
#   Windows: %APPDATA%\cowork\config.toml
#
# API keys can be set in this config file under each provider's api_key field.
# For testing, you can also pass via command line: api_key=xxx cowork

# Default provider to use when --provider is not specified
default_provider = "anthropic"

# =============================================================================
# Provider Configurations
# =============================================================================
#
# Each provider has a default API endpoint (from genai catalog):
#   anthropic:  https://api.anthropic.com/
#   openai:     https://api.openai.com/v1/
#   gemini:     https://generativelanguage.googleapis.com/v1beta/
#   deepseek:   https://api.deepseek.com/
#   groq:       https://api.groq.com/openai/v1/
#   cohere:     https://api.cohere.com/v2/
#   xai:        https://api.x.ai/v1/
#   ollama:     http://localhost:11434/
#
# Use base_url to override with a proxy or custom endpoint.

[providers.anthropic]
provider_type = "anthropic"
# api_key = "sk-ant-api03-your-key-here"
# base_url = "https://your-proxy.example.com/claude/v1/"  # Optional: proxy URL
model = "claude-sonnet-4-20250514"

[providers.openai]
provider_type = "openai"
# api_key = "sk-proj-your-key-here"
# base_url = "https://your-proxy.example.com/openai/v1/"  # Optional: proxy URL
model = "gpt-4.1"

[providers.gemini]
provider_type = "gemini"
# api_key = "your-key-here"
model = "gemini-2.5-pro"

[providers.groq]
provider_type = "groq"
# api_key = "your-key-here"
model = "llama-3.3-70b-versatile"

[providers.deepseek]
provider_type = "deepseek"
# api_key = "your-key-here"
model = "deepseek-chat"

[providers.cohere]
provider_type = "cohere"
# api_key = "your-key-here"
model = "command-r-plus"

# =============================================================================
# Approval Settings
# =============================================================================

[approval]
# Auto-approve operations up to this level: "none", "low", "medium", "high"
# "none"   = require approval for everything
# "low"    = auto-approve read operations
# "medium" = auto-approve read + write (but not delete/execute)
# "high"   = auto-approve everything (use with caution!)
auto_approve_level = "low"

# Show confirmation dialogs for tool execution
show_dialogs = true

# Timeout for approval requests (seconds)
timeout_secs = 300

# =============================================================================
# Browser Automation Settings
# =============================================================================

[browser]
# Run browser in headless mode
headless = true

# Default page load timeout (seconds)
timeout_secs = 30

# Screenshot output directory (optional)
# screenshot_dir = "/path/to/screenshots"

# =============================================================================
# General Settings
# =============================================================================

[general]
# Working directory (optional, defaults to current directory)
# workspace_dir = "/path/to/workspace"

# Log level: "error", "warn", "info", "debug", "trace"
log_level = "info"

# Enable telemetry (anonymous usage statistics)
telemetry = false

# Streaming mode for LLM responses (default: false)
# When true, responses are streamed token by token (faster perceived response)
# When false, responses are returned all at once (more accurate token counting)
# stream_mode = true
