# Cowork Configuration Example
#
# Copy this file to:
#   Linux:   ~/.config/cowork/config.toml
#   macOS:   ~/Library/Application Support/cowork/config.toml
#   Windows: %APPDATA%\cowork\config.toml
#
# API keys can be set either:
#   1. In this config file under each provider's api_key field
#   2. Via environment variables (ANTHROPIC_API_KEY, OPENAI_API_KEY, etc.)

# Default provider to use when --provider is not specified
default_provider = "anthropic"

# =============================================================================
# Provider Configurations
# =============================================================================

[providers.anthropic]
provider_type = "anthropic"
# api_key = "sk-ant-api03-your-key-here"  # Or use ANTHROPIC_API_KEY env var
api_key_env = "ANTHROPIC_API_KEY"
# base_url = "https://api.anthropic.com"  # Optional: custom API endpoint
# Models: claude-sonnet-4-20250514, claude-3-opus-20240229, claude-3-haiku-20240307
model = "claude-sonnet-4-20250514"
default_max_tokens = 4096
default_temperature = 0.7

[providers.openai]
provider_type = "openai"
# api_key = "sk-proj-your-key-here"  # Or use OPENAI_API_KEY env var
api_key_env = "OPENAI_API_KEY"
# base_url = "https://api.openai.com/v1"  # Optional: custom API endpoint
# Models: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo
model = "gpt-4o"
default_max_tokens = 4096
default_temperature = 0.7

[providers.gemini]
provider_type = "gemini"
# api_key = "your-key-here"  # Or use GEMINI_API_KEY env var
api_key_env = "GEMINI_API_KEY"
# Models: gemini-1.5-pro, gemini-1.5-flash
model = "gemini-1.5-pro"
default_max_tokens = 4096
default_temperature = 0.7

[providers.groq]
provider_type = "groq"
# api_key = "your-key-here"  # Or use GROQ_API_KEY env var
api_key_env = "GROQ_API_KEY"
# Models: llama-3.3-70b-versatile, mixtral-8x7b-32768
model = "llama-3.3-70b-versatile"
default_max_tokens = 4096
default_temperature = 0.7

[providers.deepseek]
provider_type = "deepseek"
# api_key = "your-key-here"  # Or use DEEPSEEK_API_KEY env var
api_key_env = "DEEPSEEK_API_KEY"
# Models: deepseek-chat, deepseek-coder
model = "deepseek-chat"
default_max_tokens = 4096
default_temperature = 0.7

[providers.cohere]
provider_type = "cohere"
# api_key = "your-key-here"  # Or use COHERE_API_KEY env var
api_key_env = "COHERE_API_KEY"
# Models: command-r-plus, command-r
model = "command-r-plus"
default_max_tokens = 4096
default_temperature = 0.7

# =============================================================================
# Approval Settings
# =============================================================================

[approval]
# Auto-approve operations up to this level: "none", "low", "medium", "high"
# "none"   = require approval for everything
# "low"    = auto-approve read operations
# "medium" = auto-approve read + write (but not delete/execute)
# "high"   = auto-approve everything (use with caution!)
auto_approve_level = "low"

# Show confirmation dialogs for tool execution
show_dialogs = true

# Timeout for approval requests (seconds)
timeout_secs = 300

# =============================================================================
# Browser Automation Settings
# =============================================================================

[browser]
# Run browser in headless mode
headless = true

# Default page load timeout (seconds)
timeout_secs = 30

# Screenshot output directory (optional)
# screenshot_dir = "/path/to/screenshots"

# =============================================================================
# General Settings
# =============================================================================

[general]
# Working directory (optional, defaults to current directory)
# workspace_dir = "/path/to/workspace"

# Log level: "error", "warn", "info", "debug", "trace"
log_level = "info"

# Enable telemetry (anonymous usage statistics)
telemetry = false
